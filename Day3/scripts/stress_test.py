import psycopg2
import threading
import time
import random
import os
from dotenv import load_dotenv

load_dotenv()

# --- CONFIGURATION MÃ‰TÃ‰O (Port 5434) ---
DB_CONFIG = {
  "host": "localhost",
  "port": "5434",            # <--- C'est bien le port du Day 3
  "database": "weather_db",  # <--- La base crÃ©Ã©e par le docker-compose
  "user": "meteo_user",
  "password": "password"
}

# --- REQUÃŠTES Ã€ SPAMMER ---
# On fait des calculs pour faire travailler le CPU (AVG, MAX, GROUP BY)
QUERIES = [
  # 1. Calcul de moyenne par ville (AgrÃ©gation)
  "SELECT city, AVG(temperature), MAX(humidity) FROM weather_measures GROUP BY city",

  # 2. Recherche avec filtre (Full Scan si pas d'index)
  "SELECT * FROM weather_measures WHERE temperature > 15 AND humidity < 80",

  # 3. Tri inutile pour forcer le CPU
  "SELECT * FROM weather_measures ORDER BY recorded_at DESC LIMIT 100",

  # 4. Comptage global
  "SELECT COUNT(*) FROM weather_measures"
]

def run_stress(thread_id):
  try:
    # On crÃ©e une nouvelle connexion pour chaque thread (c'est plus violent)
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    print(f"ðŸš€ Thread {thread_id} prÃªt Ã  spammer...")

    while True:
      q = random.choice(QUERIES)

      # ExÃ©cution
      cur.execute(q)
      # On force la lecture des rÃ©sultats pour charger la RAM/RÃ©seau
      cur.fetchall()

      # Pas de sleep ! On veut saturer les IOPS et le CPU.

  except Exception as e:
    print(f"âŒ Erreur Thread {thread_id}: {e}")
    # En cas d'erreur de connexion, on attend un peu
    time.sleep(1)

if __name__ == "__main__":
  print("="*50)
  print("ðŸ’£ DÃ‰MARRAGE DU STRESS TEST MÃ‰TÃ‰O (Port 5434)")
  print("Regarde ton Grafana : CPU et Transactions/sec vont monter !")
  print("="*50)

  # On lance 10 processus en parallÃ¨le pour simuler 10 utilisateurs frÃ©nÃ©tiques
  threads = []
  for i in range(10):
    t = threading.Thread(target=run_stress, args=(i,))
    t.start()
    threads.append(t)

  # Garde le script en vie
  for t in threads:
      t.join()
