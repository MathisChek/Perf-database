# üå¶Ô∏è Jour 3 : Monitoring Temps R√©el & Optimisation SQL

Ce projet finalise le cycle de TPs en mettant en place une infrastructure de monitoring compl√®te (type DevOps/SRE) pour surveiller une base de donn√©es PostgreSQL en production.

---

## üí° Pourquoi une API M√©t√©o ?

Contrairement aux TPs pr√©c√©dents bas√©s sur des donn√©es statiques (Pok√©mon), nous avons choisi ici d'utiliser l'API **OpenWeatherMap**. Cela nous permet de manipuler de la **donn√©e vivante** (Time Series) qui √©volue dans le temps, offrant un sc√©nario r√©aliste pour observer des courbes de temp√©rature et d'humidit√© en temps r√©el sur Grafana.

---

## üèóÔ∏è Architecture Technique

L'infrastructure repose sur **5 services interconnect√©s** via Docker :

| Service | R√¥le | Port |
|---------|------|------|
| üêç **Python Worker** | Robot d'ingestion qui interroge l'API toutes les 60s | - |
| üêò **PostgreSQL** | Base de donn√©es de stockage (`weather_db`) | 5434 |
| üïµÔ∏è‚Äç‚ôÇÔ∏è **Postgres Exporter** | Sonde qui expose les m√©triques techniques de la DB | 9187 |
| üíæ **Prometheus** | Base de donn√©es temporelle pour l'historique des m√©triques | 9090 |
| üìä **Grafana** | Interface de visualisation (Dashboards & Alerting) | 3000 |

---

## üìÇ Structure du Projet

```
Day3/
‚îú‚îÄ‚îÄ docker-compose.yml       # Orchestration des conteneurs
‚îú‚îÄ‚îÄ Dockerfile               # Configuration image
‚îú‚îÄ‚îÄ prometheus.yml           # Config du scraping Prometheus
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îú‚îÄ‚îÄ .env                     # Variables d'environnement (Cl√©s API, DB)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ weather_collector.py # Script d'ingestion m√©t√©o (Live)
‚îÇ   ‚îú‚îÄ‚îÄ stress_test.py       # Script de simulation de charge
‚îÇ   ‚îî‚îÄ‚îÄ indexes.sql          # Requ√™tes d'optimisation
‚îî‚îÄ‚îÄ images/                  # Captures d'√©cran pour le README
```

---

## üöÄ Guide de D√©marrage

### 1. Pr√©-requis & Outils

* **Docker** & Docker Compose (v3.8+)
* **Python 3.10+** (pour lancer les scripts clients)
* **Cl√© API OpenWeatherMap** (Gratuite)
* **Beekeeper Studio** (ou DBeaver) pour l'acc√®s SQL

### 2. Installation

Clonez le d√©p√¥t et installez les d√©pendances Python :

```bash
cd Day3
pip install -r requirements.txt
```

### 3. Configuration (.env)

Assurez-vous que le fichier `.env` est pr√©sent √† la racine du dossier `Day3` :

```ini
OPENWEATHER_API_KEY=votre_cle_api_ici
DB_HOST=localhost
DB_PORT=5434
DB_NAME=weather_db
DB_USER=meteo_user
DB_PASSWORD=password
```

### 4. Lancement de l'Infrastructure

D√©marrez la stack de monitoring (Postgres + Prometheus + Grafana) :

```bash
docker-compose up -d
```

| Interface | URL | Identifiants |
|-----------|-----|--------------|
| Grafana | http://localhost:3000 | `admin` / `admin` |
| Prometheus | http://localhost:9090 | - |

### 5. Lancement de l'Ingestion

D√©marrez le collecteur pour commencer √† remplir la base :

```bash
python3 scripts/weather_collector.py
```

### 6. Lancement du Test de Charge (Optionnel)

Pour simuler une charge r√©aliste et observer l'impact sur les m√©triques Grafana, lancez le script de stress :

```bash
python3 scripts/stress_test.py
```

Ce script simule **10 utilisateurs simultan√©s** qui ex√©cutent des requ√™tes lourdes (agr√©gations, tris, jointures) en boucle. C'est ce qui permet de visualiser les pics de charge sur le dashboard et de valider l'efficacit√© des index.

---

## üß™ Le TP : Sc√©nario "Chaos & Optimisation"

L'objectif √©tait de prouver l'efficacit√© du monitoring pour **d√©tecter et r√©soudre** des probl√®mes de performance.

### √âtape 1 : Cr√©ation de la Charge (Le Probl√®me)

Nous avons lanc√© le script `scripts/stress_test.py` qui simule **10 utilisateurs simultan√©s** effectuant des requ√™tes lourdes (agr√©gations, tris complets) sans aucun index.

> ‚ö†Ô∏è **Note importante sur le Volume de Donn√©es**
>
> Pour observer une diff√©rence significative sur les graphiques, le volume de donn√©es est critique. Avec seulement quelques milliers de lignes, PostgreSQL est trop rapide (tout tient en RAM) et les index sont inutiles. Pour ce TP, nous avons d√ª injecter **500 000 lignes** de fausses donn√©es (via `generate_series`) pour saturer le CPU et rendre les index indispensables.

### √âtape 2 : L'Optimisation (La Solution)

Sous la charge, nous avons appliqu√© les index suivants (disponibles dans `scripts/indexes.sql`) :

```sql
CREATE INDEX idx_weather_city ON weather_measures(city);
CREATE INDEX idx_weather_date ON weather_measures(recorded_at DESC);
CREATE INDEX idx_weather_temp_hum ON weather_measures(temperature, humidity);
```

> **Note** : L'index composite `idx_weather_temp_hum` est particuli√®rement utile pour les requ√™tes analytiques qui filtrent ou agr√®gent sur les deux colonnes m√©t√©o principales (ex: `WHERE temperature > 20 AND humidity < 80`).

### √âtape 3 : R√©sultats (La Preuve)

Le dashboard Grafana ci-dessous montre l'impact imm√©diat de l'optimisation :

![Dashboard Grafana - Avant/Apr√®s optimisation](images/Capture_Graphana.png)

**Observations cl√©s :**

| M√©trique | Zone "Avant" | Zone "Apr√®s" |
|----------|--------------|--------------|
| **CPU Time** | ~5.2s (en hausse) | ~200ms (chute brutale) |
| **Active Sessions** | 4-6 sessions bloqu√©es | ~2 sessions (quasi idle) |
| **Transactions/sec** | ~10 TPS | ~60 TPS (x6 !) |

Le serveur traite **plus de requ√™tes avec moins d'effort** apr√®s l'application des index.

---

## üîî Bonus : Alerting Automatique (3 R√®gles)

Pour garantir la stabilit√© de la production, nous avons configur√© **3 niveaux d'alertes** dans Grafana :

### 1. üî¥ Surcharge Connexions (Critique)

| Param√®tre | Valeur |
|-----------|--------|
| **M√©trique** | `pg_stat_activity_count` |
| **Seuil** | `> 5` sessions actives |
| **Impact** | Risque de d√©ni de service (DoS) si le pool de connexions sature |

#### Configuration de l'Alerte

**√âtape 1 : D√©finir la Query Prometheus**

![Configuration Alerte - Query](images/Alerte_config_1.png)

La requ√™te surveille le nombre de sessions actives sur `weather_db` :

```promql
sum(pg_stat_activity_count{datname="weather_db", state="active"})
```

**√âtape 2 : Configurer les Expressions (Reduce + Threshold)**

![Configuration Alerte - Expressions](images/Alerte_config_2.png)

| Expression | Type | Configuration |
|------------|------|---------------|
| **B** | Reduce | Input: `A`, Function: `Last`, Mode: `Strict` |
| **C** | Threshold | Input: `B`, Condition: `IS ABOVE 5` |

**R√©sultat : Alerte en Action**

![Preview de l'alerte](images/Alerte_preview.png)

* **√âtat Normal** : Badge vert "Normal" (sessions < 5)
* **√âtat Firing** : Badge rouge quand le seuil est d√©pass√©

La ligne rouge horizontale sur le graphique repr√©sente le seuil d'alerte configur√©.

---

### 2. üü† Cache Hit Ratio Faible (Warning)

| Param√®tre | Valeur |
|-----------|--------|
| **M√©trique** | `pg_stat_database_blks_hit` / (`blks_hit` + `blks_read`) |
| **Seuil** | `< 90%` |
| **Impact** | La base lit trop souvent sur le disque (lent) au lieu de la RAM |

```promql
pg_stat_database_blks_hit{datname="weather_db"}
/ (pg_stat_database_blks_hit{datname="weather_db"} + pg_stat_database_blks_read{datname="weather_db"})
< 0.90
```

**Action recommand√©e** : V√©rifier les index manquants ou augmenter `shared_buffers` dans la configuration PostgreSQL.

---

### 3. üü° Latence Anormale (Warning)

| Param√®tre | Valeur |
|-----------|--------|
| **M√©trique** | `pg_stat_activity_max_tx_duration` |
| **Seuil** | `> 1 seconde` |
| **Impact** | Une requ√™te bloque ou une transaction est trop longue |

```promql
pg_stat_activity_max_tx_duration{datname="weather_db"} > 1
```

**Action recommand√©e** : Identifier la requ√™te bloquante via `pg_stat_activity` et optimiser ou killer la session.

---

## üèÅ Bilan Jour 3

Ce TP a permis de connecter le monde du **d√©veloppement** (Python/SQL) √† celui des **op√©rations** (Monitoring). Nous avons d√©montr√© qu'optimiser une requ√™te SQL ne se fait pas √† l'aveugle, mais se **mesure** gr√¢ce √† des m√©triques pr√©cises :

* **CPU Time** : Temps processeur consomm√© par les requ√™tes
* **Active Sessions** : Nombre de connexions en cours d'ex√©cution
* **Transactions/sec** : D√©bit de la base de donn√©es
* **Alerting** : D√©tection automatique des anomalies

L'approche DevOps/SRE permet de **prouver par les donn√©es** l'impact d'une optimisation, plut√¥t que de se fier √† des impressions subjectives.
