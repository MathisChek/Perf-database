# üöÄ Workshop : Performance des Bases de Donn√©es & Observabilit√©

Ce d√©p√¥t contient les livrables d'un workshop intensif de **3 jours** consacr√© √† l'optimisation, la comparaison et le monitoring des bases de donn√©es modernes.

L'objectif √©tait de passer d'une approche "code-first" √† une approche **"data-centric"**, en comprenant comment les moteurs de bases de donn√©es fonctionnent sous le capot (Index, Buffers, Scan, Sharding).

---

## üìÇ Structure du Projet

Le travail est r√©parti en 3 modules distincts, chacun isolable via Docker :

```
.
‚îú‚îÄ‚îÄ Day1/                    # üìä Audit & Optimisation SQL
‚îÇ   ‚îú‚îÄ‚îÄ Sc√©nario : Plateforme E-learning (200k √©tudiants, 5M logs)
‚îÇ   ‚îî‚îÄ‚îÄ Objectif : Analyser les plans d'ex√©cution (EXPLAIN) et indexer.
‚îÇ
‚îú‚îÄ‚îÄ Day2/                    # ‚öîÔ∏è Benchmark SQL vs NoSQL
‚îÇ   ‚îú‚îÄ‚îÄ Sc√©nario : Big Data Pok√©mon (500k captures, API r√©elle)
‚îÇ   ‚îî‚îÄ‚îÄ Objectif : Comparer PostgreSQL vs MongoDB (Partitionnement, Vues Mat√©rialis√©es).
‚îÇ
‚îî‚îÄ‚îÄ Day3/                    # üì° Monitoring & SRE
    ‚îú‚îÄ‚îÄ Sc√©nario : Ingestion M√©t√©o Temps R√©el (OpenWeatherMap)
    ‚îî‚îÄ‚îÄ Objectif : Infrastructure Prometheus/Grafana et Alerting en production.
```

---

## üìÖ D√©tail des Modules

### Jour 1 : Audit de S√©curit√© & Indexation B-Tree

**Contexte** : Une base de donn√©es d'√©cole en ligne souffre de lenteurs critiques.

**R√©alisations** :
* G√©n√©ration de donn√©es massives (5M lignes)
* Audit des requ√™tes lentes via `EXPLAIN (ANALYZE, BUFFERS)`
* Mise en place d'une strat√©gie d'indexation (Composite, Covering Index)

**Apprentissage cl√©** : Le paradoxe de la r√©gression ‚Äî pourquoi un index peut parfois ralentir une requ√™te sans `LIMIT`.

---

### Jour 2 : PostgreSQL vs MongoDB

**Contexte** : Stockage de logs de jeux (Pok√©mon) avec des donn√©es g√©ospatiales et JSON imbriqu√©.

**R√©alisations** :
* Script d'ingestion Python (ETL) depuis l'API Pok√©API
* Benchmark de performance : `Seq Scan` vs `COLLSCAN`
* Optimisation avanc√©e : Partitionnement Temporel (SQL) et Indexation JSON (Mongo)

**Apprentissage cl√©** : MongoDB excelle sur la lecture unitaire (Document), PostgreSQL domine sur l'analytique (Agr√©gations).

---

### Jour 3 : Monitoring Industriel & Alerting

**Contexte** : Surveillance d'une application m√©t√©o "Live" en production.

**R√©alisations** :
* D√©ploiement d'une stack SRE : Postgres Exporter + Prometheus + Grafana
* Stress Test : Simulation de 10 utilisateurs concurrents
* Preuve visuelle de l'optimisation (Chute de la charge CPU et des sessions actives)
* Configuration d'alertes (Surcharge connexions, Cache Hit Ratio)

**Apprentissage cl√©** : On n'optimise pas √† l'aveugle, on optimise ce qu'on mesure.

---

## üõ†Ô∏è Stack Technique Globale

| Cat√©gorie | Technologies |
|-----------|--------------|
| **Langages** | Python 3.10, SQL, JavaScript (Mongosh) |
| **Bases de donn√©es** | PostgreSQL 15, MongoDB 6 |
| **Outils SRE** | Prometheus, Grafana, Docker & Docker Compose |
| **Clients** | Beekeeper Studio, MongoDB Compass |

---

## üöÄ Installation G√©n√©rale

Chaque dossier (`Day1`, `Day2`, `Day3`) est ind√©pendant et poss√®de son propre `docker-compose.yml`.

Pour lancer un module :

```bash
# Exemple pour le Jour 3
cd Day3
docker-compose up -d
pip install -r requirements.txt
python3 scripts/weather_collector.py
```

---

> Projet r√©alis√© dans le cadre du module "Performance des SGBD".
