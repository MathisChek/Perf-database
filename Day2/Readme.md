# âš¡ Benchmark SQL vs NoSQL : PokÃ©mon Database

Ce projet a pour but de comparer les performances entre une base relationnelle (**PostgreSQL**) et une base orientÃ©e documents (**MongoDB**) sur un volume de donnÃ©es significatif (**500 000 enregistrements**).

Le scÃ©nario simule les logs d'un jeu type "PokÃ©mon GO" : des captures de PokÃ©mon effectuÃ©es par des dresseurs Ã  des coordonnÃ©es GPS variÃ©es, avec diffÃ©rentes mÃ©tÃ©os.

---

## ğŸš€ Guide de DÃ©marrage

Voici la procÃ©dure pas-Ã -pas pour installer le projet, gÃ©nÃ©rer les donnÃ©es et lancer les tests de performance.

### 1. PrÃ©-requis

* **Docker** & Docker Compose
* **Python 3.8+**
* Un client SQL (ex: Beekeeper Studio) et un client Mongo (MongoDB Compass)

### 2. Installation

Clonez le dÃ©pÃ´t et installez les dÃ©pendances Python nÃ©cessaires :

```bash
git clone https://github.com/votre-repo/perf-database.git
cd perf-database
pip install psycopg2-binary pymongo python-dotenv faker requests terminaltables
```

### 3. Configuration (.env)

CrÃ©ez un fichier `.env` Ã  la racine du projet.

> **Attention** : Pour Ã©viter les erreurs de connexion Docker en local, utilisez l'IP `127.0.0.1` et forcez la source d'authentification pour MongoDB.

```ini
# --- PostgreSQL Local ---
POSTGRES_USER=etudiant
POSTGRES_PASSWORD=password
POSTGRES_DB=pokedb
POSTGRES_PORT=5433

# --- MongoDB Local ---
# Note : on utilise 127.0.0.1 et directConnection pour Ã©viter les Ã©checs de rÃ©solution DNS
MONGO_URI="mongodb://etudiant:password@127.0.0.1:27017/?authSource=admin&directConnection=true"
```

### 4. Lancement de l'Infrastructure

DÃ©marrez les conteneurs (Postgres et Mongo) :

```bash
docker-compose up -d
```

### 5. Ingestion des DonnÃ©es (GÃ©nÃ©ration)

Avant de lancer le script Python, vous devez crÃ©er la base de donnÃ©es SQL manuellement (le script ne peut pas crÃ©er la base s'il ne peut pas s'y connecter).

1. Connectez-vous Ã  PostgreSQL (`localhost:5433`, user: `etudiant`, pass: `password`)
2. ExÃ©cutez la commande SQL : `CREATE DATABASE pokedb;`
3. Lancez le script d'ingestion :

```bash
python3 Day2/ingest.py
```

Ce script tÃ©lÃ©charge les infos rÃ©elles depuis l'API PokÃ©mon, gÃ©nÃ¨re 500 000 captures alÃ©atoires et peuple les deux bases simultanÃ©ment pour assurer une Ã©galitÃ© parfaite des donnÃ©es.

### 6. Lancer le Benchmark

Pour exÃ©cuter les 5 requÃªtes de test et voir les temps de rÃ©ponse :

```bash
python3 benchmark.py
```

---

## ğŸ“‚ ModÃ©lisation des DonnÃ©es

### ğŸ˜ PostgreSQL : ModÃ¨le en Ã‰toile (NormalisÃ©)

Pour Ã©viter la redondance, nous utilisons une structure relationnelle classique :

* **fact_captures** (500k lignes) : Contient l'Ã©vÃ©nement (Date, Lat, Long, MÃ©tÃ©o) et une ClÃ© Ã‰trangÃ¨re vers le PokÃ©mon.
* **dim_pokemons** (151 lignes) : Contient les infos fixes (Nom, Type, Stats).

**ConsÃ©quence** : Jointure (`JOIN`) obligatoire pour rÃ©cupÃ©rer le nom du PokÃ©mon.

### ğŸƒ MongoDB : ModÃ¨le ImbriquÃ© (DÃ©normalisÃ©)

Nous privilÃ©gions la lecture rapide :

* **Collection captures** (500k documents) : Chaque document contient l'Ã©vÃ©nement ET la fiche complÃ¨te du PokÃ©mon capturÃ© (sous-objet JSON).

**ConsÃ©quence** : Pas de jointure, mais forte duplication de donnÃ©es (le mot "Pikachu" est stockÃ© des milliers de fois).

---

## ğŸ“Š Phase 1 : Analyse du Stockage

| CritÃ¨re | PostgreSQL | MongoDB (WiredTiger) |
|---------|------------|----------------------|
| Nombre de lignes | 500 000 | 500 000 |
| Taille Disque | 50 MB | 43.1 MB ğŸ† |

**Observation** : Contre toute attente, MongoDB est plus lÃ©ger.

**Explication** : Bien que MongoDB duplique les donnÃ©es, son moteur de stockage (WiredTiger) utilise par dÃ©faut la compression Snappy, trÃ¨s efficace sur les rÃ©pÃ©titions de texte dans les documents JSON. PostgreSQL stocke les donnÃ©es brutes sans compression par dÃ©faut.

---

## ğŸï¸ Phase 2 : Performance sans Index (Brute Force)

Dans cette phase, aucun index n'est crÃ©Ã©. Les moteurs doivent scanner l'intÃ©gralitÃ© du disque ("Full Scan") pour trouver les rÃ©ponses.

| ScÃ©nario | PostgreSQL (ms) | MongoDB (ms) | Vainqueur |
|----------|-----------------|--------------|-----------|
| 1. Recherche Exacte (Pikachu) | 35.64 ms | 245 ms | ğŸ˜ SQL |
| 2. Intervalle (Lat > 45) | 86.52 ms | 258 ms | ğŸ˜ SQL |
| 3. AgrÃ©gation (Count MÃ©tÃ©o) | 50.69 ms | 498 ms | ğŸ˜ SQL |
| 4. Complexe (Electric + Rainy) | 36.35 ms | 271 ms | ğŸ˜ SQL |
| 5. AgrÃ©gation Lourde (Avg HP) | 84.15 ms | 724 ms | ğŸ˜ SQL |

**Analyse** : Sur un scan complet, PostgreSQL Ã©crase MongoDB. Lire des lignes SQL simples ("tuples") est beaucoup moins coÃ»teux pour le CPU que de parser 500 000 documents JSON imbriquÃ©s.

### ğŸ”¬ Comprendre les Types de Scan

Pour expliquer cet Ã©cart de performance, il faut comprendre comment chaque moteur parcourt les donnÃ©es sans index.

#### PostgreSQL : Sequential Scan (Seq Scan)

```sql
EXPLAIN ANALYZE SELECT * FROM fact_captures WHERE pokemon_id = 25;
-- Seq Scan on fact_captures  (cost=0.00..12847.00 rows=3289 width=36)
--   Filter: (pokemon_id = 25)
```

PostgreSQL effectue un **Sequential Scan** : il lit les pages disque de maniÃ¨re linÃ©aire, tuple par tuple. Chaque ligne est un enregistrement binaire Ã  taille fixe avec des colonnes typÃ©es. Le moteur n'a qu'Ã  :

1. Lire le bloc disque (8 Ko par dÃ©faut)
2. Extraire directement les valeurs des colonnes via leur offset mÃ©moire
3. Appliquer le filtre sur une donnÃ©e dÃ©jÃ  typÃ©e (integer, float, varchar...)

Le coÃ»t CPU est minimal car il n'y a **aucun parsing** : les donnÃ©es sont stockÃ©es dans un format binaire optimisÃ©, prÃªt Ã  Ãªtre comparÃ©.

#### MongoDB : Collection Scan (COLLSCAN)

```javascript
db.captures.find({ "pokemon.name": "Pikachu" }).explain("executionStats")
// "stage": "COLLSCAN"
// "docsExamined": 500000
```

MongoDB effectue un **Collection Scan** : il parcourt tous les documents de la collection. Mais contrairement Ã  SQL, chaque document est un objet BSON (Binary JSON) de taille variable avec une structure flexible. Pour chaque document, le moteur doit :

1. Lire le document BSON depuis le disque
2. **Parser la structure** pour localiser le champ recherchÃ© (ex: `pokemon.name`)
3. Naviguer dans l'arborescence imbriquÃ©e (ici, descendre dans le sous-objet `pokemon`)
4. DÃ©coder la valeur et effectuer la comparaison

Ce parsing dynamique, rÃ©pÃ©tÃ© 500 000 fois, gÃ©nÃ¨re un **overhead CPU significatif**.

#### Comparaison visuelle

| Aspect | PostgreSQL (Seq Scan) | MongoDB (COLLSCAN) |
|--------|----------------------|---------------------|
| Format de stockage | Tuples binaires Ã  colonnes fixes | Documents BSON de taille variable |
| AccÃ¨s aux champs | Offset direct en mÃ©moire | Parsing + navigation dans l'arbre |
| CoÃ»t par enregistrement | ~1 opÃ©ration (lecture) | ~3-5 opÃ©rations (lecture + parsing + navigation) |
| AdaptÃ© pour | DonnÃ©es tabulaires homogÃ¨nes | DonnÃ©es flexibles et imbriquÃ©es |

#### Pourquoi l'Ã©cart se creuse sur les agrÃ©gations ?

Sur les requÃªtes 3 et 5 (COUNT, AVG), PostgreSQL utilise des optimisations supplÃ©mentaires :

* **Vectorisation** : traitement par lots de valeurs plutÃ´t qu'une par une
* **Types natifs** : les calculs sur `INTEGER` ou `FLOAT` sont des opÃ©rations CPU primitives
* **Pas de dÃ©sÃ©rialisation** : les valeurs numÃ©riques sont directement exploitables

MongoDB, avec son Aggregation Pipeline, doit dÃ©sÃ©rialiser chaque valeur BSON avant de l'accumuler, ce qui multiplie le coÃ»t par document.

---

## ğŸ”§ Phase 3 : Performance AVEC Index (OptimisÃ©)

Nous avons crÃ©Ã© des index B-Tree sur Postgres et des index spÃ©cifiques sur les champs imbriquÃ©s dans Mongo.

### Index crÃ©Ã©s

```sql
-- PostgreSQL
CREATE INDEX idx_pokemon_id ON fact_captures(pokemon_id);
CREATE INDEX idx_latitude ON fact_captures(latitude);
CREATE INDEX idx_weather ON fact_captures(weather);
```

```javascript
// MongoDB
db.captures.createIndex({ "pokemon.name": 1 })
db.captures.createIndex({ "latitude": 1 })
db.captures.createIndex({ "weather": 1 })
```

### RÃ©sultats finaux

| ScÃ©nario | PostgreSQL (IndexÃ©) | MongoDB (IndexÃ©) | Vainqueur |
|----------|---------------------|------------------|-----------|
| 1. Recherche Exacte (Pikachu) | 14.51 ms | 8 ms âš¡ | ğŸƒ MONGO |
| 2. Intervalle (Lat > 45) | 75.43 ms | 447 ms | ğŸ˜ SQL |
| 3. AgrÃ©gation (Count MÃ©tÃ©o) | 61.08 ms | 546 ms | ğŸ˜ SQL |
| 4. Complexe (Electric + Rainy) | 50.44 ms | 20 ms âš¡ | ğŸƒ MONGO |
| 5. AgrÃ©gation Lourde (Avg HP) | 112.05 ms | 752 ms | ğŸ˜ SQL |

### ğŸ”¬ Comprendre les Types de Scan avec Index

#### PostgreSQL : Index Scan + Heap Fetch

```sql
EXPLAIN ANALYZE SELECT * FROM fact_captures fc
JOIN dim_pokemons dp ON fc.pokemon_id = dp.id
WHERE dp.name = 'Pikachu';
-- Index Scan using idx_pokemon_id on fact_captures
-- Nested Loop Join with dim_pokemons
```

Avec un index, PostgreSQL effectue un **Index Scan** en deux temps :

1. **Parcours de l'index B-Tree** : localise les `pokemon_id` correspondants (trÃ¨s rapide, O(log n))
2. **Heap Fetch** : pour chaque entrÃ©e trouvÃ©e, retourne dans la table principale (le "heap") rÃ©cupÃ©rer la ligne complÃ¨te
3. **Nested Loop Join** : pour chaque ligne, fait une jointure avec `dim_pokemons` pour rÃ©cupÃ©rer le nom

C'est cette Ã©tape de jointure qui pÃ©nalise PostgreSQL sur la requÃªte 1.

#### MongoDB : Index Scan + Document Direct

```javascript
db.captures.find({ "pokemon.name": "Pikachu" }).explain("executionStats")
// "stage": "IXSCAN" â†’ "stage": "FETCH"
// "keysExamined": 3289, "docsExamined": 3289
```

MongoDB avec index effectue :

1. **IXSCAN** : parcours de l'index B-Tree sur `pokemon.name`
2. **FETCH** : rÃ©cupÃ©ration directe du document complet

**Pas de jointure nÃ©cessaire** : le document contient dÃ©jÃ  toutes les informations (nom, stats, date de capture...). C'est le bÃ©nÃ©fice direct du modÃ¨le dÃ©normalisÃ©.

#### Pourquoi MongoDB gagne sur la recherche unitaire ?

| Ã‰tape | PostgreSQL | MongoDB |
|-------|-----------|---------|
| 1. TraversÃ©e index | âœ… O(log n) | âœ… O(log n) |
| 2. RÃ©cupÃ©ration donnÃ©es | Heap fetch (table faits) | Document fetch (complet) |
| 3. Jointure | âš ï¸ Lookup vers dim_pokemons | âŒ Non nÃ©cessaire |
| 4. Assemblage rÃ©sultat | Fusion des deux tables | DÃ©jÃ  prÃªt |

Le modÃ¨le imbriquÃ© de MongoDB Ã©limine complÃ¨tement l'Ã©tape de jointure, ce qui fait la diffÃ©rence sur les lectures unitaires.

#### Pourquoi PostgreSQL domine toujours sur les agrÃ©gations ?

MÃªme avec index, les requÃªtes analytiques (COUNT, AVG, filtres sur plages) favorisent PostgreSQL :

* **Index-Only Scan** : PostgreSQL peut parfois rÃ©pondre uniquement depuis l'index sans toucher au heap
* **Bitmap Index Scan** : pour les grandes plages, PostgreSQL construit un bitmap en mÃ©moire puis fait un seul passage sur le disque
* **Parallel Seq Scan** : PostgreSQL peut parallÃ©liser les agrÃ©gations sur plusieurs CPU cores

MongoDB, mÃªme indexÃ©, doit toujours fetch et parser les documents BSON pour extraire les valeurs Ã  agrÃ©ger.

---

## ğŸ•µï¸â€â™‚ï¸ Analyse et Conclusion

### Le K.O. technique de MongoDB (Recherches ciblÃ©es)

Sur les requÃªtes 1 ("Trouver Pikachu") et 4 ("Electric + Rainy"), MongoDB est respectivement **1.8x** et **2.5x plus rapide** que SQL.

**Pourquoi ?** Ces deux requÃªtes partagent un point commun : elles filtrent sur des champs **contenus dans le document** (`pokemon_details.name`, `pokemon_details.type`, `weather`). Une fois l'index trouvÃ©, Mongo lit le document et a dÃ©jÃ  toutes les infos nÃ©cessaires. PostgreSQL, mÃªme indexÃ©, doit faire une Ã©tape supplÃ©mentaire : la **Jointure** entre la table des faits et la dimension pour rÃ©cupÃ©rer le type du PokÃ©mon. C'est lÃ  que le NoSQL brille.

### La domination de SQL (Analytique)

DÃ¨s qu'il s'agit de compter, filtrer sur des plages ou faire des moyennes (RequÃªtes 2, 3, 5), PostgreSQL reste supÃ©rieur. Son moteur est optimisÃ© pour les calculs mathÃ©matiques sur des colonnes typÃ©es, lÃ  oÃ¹ l'Aggregation Pipeline de Mongo demande plus de ressources mÃ©moire.

---

## ğŸ† Verdict

* **Utilisez MongoDB** pour des accÃ¨s directs Ã  des objets complets (Profil utilisateur, Catalogue produit, Fiche dÃ©taillÃ©e).
* **Utilisez PostgreSQL** pour des requÃªtes analytiques, des statistiques et des relations complexes.
